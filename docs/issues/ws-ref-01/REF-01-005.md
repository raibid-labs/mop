# REF-01-005: HTTP REST API - Integration Tests

## Context
Create comprehensive integration tests for the HTTP REST API that verify end-to-end functionality, including middleware, error handling, and performance characteristics. Tests should validate behavior that OBI will observe in production.

## Requirements
- [ ] Set up integration test framework with testcontainers (optional) or in-memory
- [ ] Test all CRUD operations (create, read, update, delete)
- [ ] Test pagination with various limit/offset values
- [ ] Test search functionality with different queries
- [ ] Test rate limiting behavior (verify 429 responses)
- [ ] Test error handling (404, 500, validation errors)
- [ ] Test slow endpoint (verify 1-3s latency)
- [ ] Test concurrent requests (race conditions)
- [ ] Test health endpoint behavior
- [ ] Add performance benchmarks (requests per second)
- [ ] Generate test coverage report (target 80%+)

## Acceptance Criteria
1. All integration tests pass consistently
2. Test coverage >= 80% for handlers and middleware
3. Concurrent request tests pass without data corruption
4. Rate limiting test verifies 429 after threshold
5. Slow endpoint test measures latency correctly
6. Health endpoint test covers liveness/readiness scenarios
7. Error scenarios produce expected responses
8. Benchmark tests establish baseline performance
9. Tests can run in CI/CD pipeline
10. Test documentation explains what each test validates

## Clarifying Questions

**Q1: Should we use a real server or httptest?**
- Context: Integration vs unit test trade-off
- Options:
  - A) httptest.Server (fast, isolated)
  - B) Real server on random port (realistic)
  - C) Both (unit tests use httptest, integration uses real)
- Default: Real server for true integration testing

**Q2: Should we use testcontainers for dependencies?**
- Context: This example has no external dependencies
- Options:
  - A) Not needed (in-memory store)
  - B) Add for future-proofing
  - C) Document pattern for SQL/Redis examples
- Default: Not needed here, document pattern for future

**Q3: What performance benchmarks should we include?**
- Context: Baseline for OBI overhead measurement
- Options:
  - A) Requests per second only
  - B) Latency percentiles (p50, p95, p99)
  - C) Both + memory usage
- Default: Both RPS and latency percentiles

**Q4: Should tests clean up data between runs?**
- Context: Test isolation and repeatability
- Options:
  - A) Reset store before each test (isolated)
  - B) Use separate store per test (parallel-safe)
  - C) No cleanup (faster but fragile)
- Default: Separate store per test for parallel execution

## Technical Notes

### Files to Create
```
tests/
├── integration_test.go          # Main integration tests
├── benchmark_test.go            # Performance benchmarks
├── concurrent_test.go           # Concurrency tests
└── helpers.go                   # Test utilities
```

### Test Structure
```go
// tests/integration_test.go
func TestIntegration(t *testing.T) {
    // Start server
    server := startTestServer(t)
    defer server.Shutdown()

    baseURL := "http://localhost:" + server.Port

    // Run test suites
    t.Run("CRUD Operations", func(t *testing.T) {
        testCreateProduct(t, baseURL)
        testGetProduct(t, baseURL)
        testUpdateProduct(t, baseURL)
        testDeleteProduct(t, baseURL)
    })

    t.Run("Pagination", func(t *testing.T) {
        testPagination(t, baseURL)
    })

    t.Run("Search", func(t *testing.T) {
        testSearch(t, baseURL)
    })

    t.Run("Rate Limiting", func(t *testing.T) {
        testRateLimit(t, baseURL)
    })

    t.Run("Error Handling", func(t *testing.T) {
        test404(t, baseURL)
        test500(t, baseURL)
        testValidation(t, baseURL)
    })

    t.Run("Performance", func(t *testing.T) {
        testSlowEndpoint(t, baseURL)
    })
}
```

### Example Test Cases
```go
func testCreateProduct(t *testing.T, baseURL string) {
    product := map[string]interface{}{
        "name":        "Test Product",
        "description": "Test Description",
        "price":       99.99,
        "stock":       100,
    }

    body, _ := json.Marshal(product)
    resp, err := http.Post(baseURL+"/products", "application/json", bytes.NewBuffer(body))
    require.NoError(t, err)
    defer resp.Body.Close()

    assert.Equal(t, 201, resp.StatusCode)

    var created map[string]interface{}
    json.NewDecoder(resp.Body).Decode(&created)
    assert.NotEmpty(t, created["id"])
    assert.Equal(t, "Test Product", created["name"])
}

func testRateLimit(t *testing.T, baseURL string) {
    // Make rapid requests
    var responses []*http.Response
    for i := 0; i < 150; i++ {
        resp, err := http.Get(baseURL + "/health")
        require.NoError(t, err)
        responses = append(responses, resp)
    }

    // Verify some were rate limited
    rateLimited := 0
    for _, resp := range responses {
        if resp.StatusCode == 429 {
            rateLimited++
        }
        resp.Body.Close()
    }

    assert.Greater(t, rateLimited, 0, "Expected some requests to be rate limited")
}

func testSlowEndpoint(t *testing.T, baseURL string) {
    start := time.Now()
    resp, err := http.Get(baseURL + "/slow")
    duration := time.Since(start)

    require.NoError(t, err)
    defer resp.Body.Close()

    assert.Equal(t, 200, resp.StatusCode)
    assert.GreaterOrEqual(t, duration, 1*time.Second)
    assert.LessOrEqual(t, duration, 4*time.Second) // 3s + tolerance
}
```

### Concurrent Testing
```go
func TestConcurrentRequests(t *testing.T) {
    server := startTestServer(t)
    defer server.Shutdown()

    baseURL := "http://localhost:" + server.Port

    // Create product concurrently
    var wg sync.WaitGroup
    errors := make(chan error, 100)

    for i := 0; i < 100; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()

            product := map[string]interface{}{
                "name":  fmt.Sprintf("Product %d", id),
                "price": float64(id),
                "stock": id,
            }

            body, _ := json.Marshal(product)
            resp, err := http.Post(baseURL+"/products", "application/json", bytes.NewBuffer(body))
            if err != nil {
                errors <- err
                return
            }
            defer resp.Body.Close()

            if resp.StatusCode != 201 {
                errors <- fmt.Errorf("expected 201, got %d", resp.StatusCode)
            }
        }(i)
    }

    wg.Wait()
    close(errors)

    // Check for errors
    for err := range errors {
        t.Error(err)
    }
}
```

### Benchmark Tests
```go
func BenchmarkGetProducts(b *testing.B) {
    server := startTestServer(b)
    defer server.Shutdown()

    baseURL := "http://localhost:" + server.Port

    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        resp, _ := http.Get(baseURL + "/products")
        resp.Body.Close()
    }
}
```

### Testing Approach
```bash
# Run all tests
go test ./tests/... -v

# Run with coverage
go test ./tests/... -coverprofile=coverage.out
go tool cover -html=coverage.out

# Run benchmarks
go test ./tests/... -bench=. -benchmem

# Run race detector
go test ./tests/... -race
```

### Dependencies
- `github.com/stretchr/testify` - Assertions
- Standard library `net/http/httptest`
- Standard library `testing`

### Integration Points
- Tests handlers from REF-01-002
- Tests middleware from REF-01-003
- Uses deployment patterns from REF-01-004
- Baseline for OBI overhead measurement
- Performance benchmarks feed into REF-07-004

## Definition of Done
- [ ] All integration tests implemented and passing
- [ ] Test coverage >= 80% for handlers and middleware
- [ ] Concurrent tests verify thread safety
- [ ] Rate limiting test validates behavior
- [ ] Slow endpoint test measures latency
- [ ] Benchmark tests establish baseline performance
- [ ] All tests pass locally and in CI
- [ ] Race detector finds no issues (`-race` flag)
- [ ] Coverage report generated and reviewed
- [ ] Test documentation explains scenarios
- [ ] README updated with test instructions
- [ ] Code reviewed for test quality
- [ ] PR merged to main branch

## Related Issues
- Blocked by: REF-01-002 (needs handlers)
- Blocked by: REF-01-003 (needs middleware)
- Related: REF-01-006 (test data appears in dashboard)
- Related: REF-06-001 (load tests use similar patterns)

## Labels
`workstream:ws-ref-01`, `priority:high`, `status:new`, `type:testing`, `protocol:http`
